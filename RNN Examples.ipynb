{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of RNN Approaches\n",
    "(see https://distill.pub/2016/augmented-rnns/)\n",
    "\n",
    "This creates a sample task, based on number sequences, and\n",
    "different goals to compare the performance of vanilla RNN's,\n",
    "LSTM's, NTM's, and attention based networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, einsum\n",
    "from random import randint\n",
    "from torch.nn import functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.Numbers import Numbers\n",
    "from models import BasicRNN\n",
    "from models import BasicLSTM\n",
    "\n",
    "from models.MemoryNN import MemoryNN\n",
    "\n",
    "from training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTM_LSTM(nn.Module):\n",
    "    '''  '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 memory_banks, memory_dim, output_length = 1):\n",
    "        ''' Init the NTM-LSTM '''\n",
    "        super(NTM_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.memory_banks = memory_banks\n",
    "        self.memory_dim = memory_dim\n",
    "        self.output_length = output_length\n",
    "        \n",
    "        # Core LSTM and Memory\n",
    "        self.lstm = nn.LSTM(input_size + memory_dim, hidden_size)\n",
    "        self.add_module('mem_nn', MemoryNN(hidden_size, memory_banks, memory_dim))\n",
    "        #self.mem_nn = MemoryNN(hidden_size, memory_banks, memory_dim)\n",
    "        \n",
    "        # Output Layer\n",
    "        self.hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, state):\n",
    "        ''' Run a forward path for a single number of sequence of numbers\n",
    "        \n",
    "        Args:\n",
    "            state: contains [hidden, cell, memory, last_weight]\n",
    "        \n",
    "        Returns:\n",
    "            output and hidden layer after last sequence input\n",
    "        '''\n",
    "        output = []\n",
    "        hidden, cell, memory, weight = state\n",
    "        \n",
    "        for i in range(input.shape[0]):\n",
    "            ntm_input = torch.cat((input[i].unsqueeze(0), memory.view(1,1,-1)), dim=2)\n",
    "        \n",
    "            _, (hidden, cell) = self.lstm.forward(ntm_input, (hidden, cell))\n",
    "            memory, weight = self.mem_nn.forward(hidden, weight)\n",
    "        \n",
    "        output.append(self.softmax(self.hidden_to_output(hidden)))\n",
    "        \n",
    "        for j in range(1, self.output_length):\n",
    "            ntm_input = torch.cat((output[-1], memory.view(1,1,-1)), dim=2)\n",
    "        \n",
    "            _, (hidden, cell) = self.lstm.forward(ntm_input, (hidden, cell))\n",
    "            memory, weight = self.mem_nn.forward(hidden, weight)\n",
    "            output.append(self.softmax(self.hidden_to_output(hidden)))\n",
    "            \n",
    "        output = torch.cat(output, dim=0)\n",
    "        return output, (hidden, cell, memory, weight)\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        ''' Returns new hidden layers for the start of a new sequence '''\n",
    "        memory, weight = self.mem_nn.reset_memory()\n",
    "        \n",
    "        model_device = next(self.parameters()).device\n",
    "\n",
    "        return (\n",
    "            torch.randn(1, 1, self.hidden_size).to(model_device),\n",
    "            torch.randn(1, 1, self.hidden_size).to(model_device),\n",
    "            memory.to(model_device),\n",
    "            weight.to(model_device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number Generator + Goal Setup\n",
    "max_number = 9\n",
    "goal_func = lambda stream: stream[0]\n",
    "\n",
    "'''number_tool = Numbers(\n",
    "    max_number,\n",
    "    reset_value_func = lambda x: randint(0,max_number),\n",
    "    goal_func = goal_func\n",
    ")'''\n",
    "\n",
    "number_tool = Numbers(\n",
    "    max_number,\n",
    "    increment_func = lambda incr: randint(0,9),\n",
    "    goal_func = lambda stream: stream[0:3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Size\n",
    "train_size = 100e3\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_kwargs = {\n",
    "    'train_size': train_size,\n",
    "    'number_tool': number_tool,\n",
    "    'criterion': criterion,\n",
    "    'stream_size': 200,\n",
    "    'model': None,\n",
    "    'optim': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Vanilla RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = BasicRNN(number_tool.get_dim(), 5, number_tool.get_dim(), output_length = 3)\n",
    "rnn.to(device)\n",
    "\n",
    "rnn_optim = torch.optim.SGD(rnn.parameters(), lr = 0.001)\n",
    "\n",
    "rnn_kwargs = setup_kwargs.copy()\n",
    "rnn_kwargs['model'] = rnn\n",
    "rnn_kwargs['optim'] = rnn_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Error: tensor(0.0031, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-322d2903cda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrnn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/rnn_exploration/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, number_tool, criterion, optim, train_size, stream_size, print_interval)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Generate a new random sequence for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Reset the model gradients and hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rnn_exploration/tasks/Numbers.py\u001b[0m in \u001b[0;36mencode_stream\u001b[0;34m(self, num_stream)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_numbers\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvalid_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(**rnn_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BasicLSTM(number_tool.get_dim(), 5, number_tool.get_dim(), output_length = 3)\n",
    "lstm.to(device)\n",
    "\n",
    "lstm_optim = torch.optim.SGD(lstm.parameters(), lr = 0.001, momentum = 0.9)\n",
    "\n",
    "lstm_kwargs = setup_kwargs.copy()\n",
    "lstm_kwargs['model'] = lstm\n",
    "lstm_kwargs['optim'] = lstm_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Error: tensor(0.0026, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1439431cc6a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlstm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/rnn_exploration/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, number_tool, criterion, optim, train_size, stream_size, print_interval)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Run backprop with the errors and update model/trackers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0merror_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(**lstm_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Turing Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_banks = 10\n",
    "memory_dim = 20\n",
    "\n",
    "ntm = NTM_LSTM(number_tool.get_dim(), 5, number_tool.get_dim(),\n",
    "               memory_banks, memory_dim, output_length = 3)\n",
    "ntm.to(device)\n",
    "\n",
    "ntm_optim = torch.optim.SGD(ntm.parameters(), lr = 0.001, momentum = 0.9)\n",
    "\n",
    "ntm_kwargs = setup_kwargs.copy()\n",
    "ntm_kwargs['model'] = ntm\n",
    "ntm_kwargs['optim'] = ntm_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m(2217)\u001b[0;36mcosine_similarity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2215 \u001b[0;31m        \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2216 \u001b[0;31m    \"\"\"\n",
      "\u001b[0m\u001b[0;32m-> 2217 \u001b[0;31m    \u001b[0mw12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2218 \u001b[0;31m    \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2219 \u001b[0;31m    \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jupyter/rnn_exploration/models/Memory.py\u001b[0m(60)\u001b[0;36mget_content_similarity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     58 \u001b[0;31m            \u001b[0mkey_strength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0mto\u001b[0m \u001b[0mamplify\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mattenuate\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m        '''\n",
      "\u001b[0m\u001b[0;32m---> 60 \u001b[0;31m        \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     61 \u001b[0;31m        \u001b[0mcontent_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_strength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     62 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mcontent_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self._buffer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'Memory' object has no attribute '_buffer'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self._buffers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('memory', tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]]))])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory()\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.buffers()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'Memory' object has no attribute 'buffers'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jupyter/rnn_exploration/models/MemoryNN.py\u001b[0m(63)\u001b[0;36mcalculate_memory_weight\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     61 \u001b[0;31m            \u001b[0mγ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msharpening\u001b[0m \u001b[0mexponent\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     62 \u001b[0;31m        '''\n",
      "\u001b[0m\u001b[0;32m---> 63 \u001b[0;31m        \u001b[0mw_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_content_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mβ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     64 \u001b[0;31m        \u001b[0mw_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m        \u001b[0mw_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemoryNN(\n",
      "  (memory): Memory()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax()\n",
      "  (hidden_to_dim): Linear(in_features=5, out_features=65, bias=True)\n",
      "  (hidden_to_gate): Linear(in_features=5, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bec561612fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'debug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mntm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/rnn_exploration/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, number_tool, criterion, optim, train_size, stream_size, print_interval)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Score the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Determine the target output and calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c9718182cdac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, state)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntm_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_to_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rnn_exploration/models/MemoryNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden, last_weight)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shift'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mγ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sharpening'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rnn_exploration/models/MemoryNN.py\u001b[0m in \u001b[0;36mcalculate_memory_weight\u001b[0;34m(self, w_old, k, β, g, s, γ)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mγ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msharpening\u001b[0m \u001b[0mexponent\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         '''\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mw_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_content_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mβ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mw_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mw_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rnn_exploration/models/Memory.py\u001b[0m in \u001b[0;36mget_content_similarity\u001b[0;34m(self, query, key_strength)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mkey_strength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0mto\u001b[0m \u001b[0mamplify\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mattenuate\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         '''\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mcontent_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_strength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontent_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(x1, x2, dim, eps)\u001b[0m\n\u001b[1;32m   2215\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \"\"\"\n\u001b[0;32m-> 2217\u001b[0;31m     \u001b[0mw12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m     \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "%debug\n",
    "train_model(**ntm_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Functional Testing\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing _convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for _convolve\n",
    "s = torch.tensor([1.,0.,0.])\n",
    "x = torch.tensor([0.40, .05, .50, 0, 0, .05])\n",
    "\n",
    "print(x)\n",
    "_convolve(x,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Sequence Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 0, 2, 1, 4, 2, 5, 8, 0, 5, 8, 3, 8, 7, 2, 4, 9, 0, 6, 3, 4, 0, 7, 7, 4, 6, 0, 7, 4, 'END']\n",
      "[0, 9, 0]\n"
     ]
    }
   ],
   "source": [
    "# Testing for criterion = nn.NLLLoss()\n",
    "\n",
    "n = Numbers(increment_func = lambda incr: randint(0,9), goal_func = lambda stream: stream[0:3])\n",
    "stream = n.create_stream(30)\n",
    "enc_stream = n.encode_stream(stream)\n",
    "\n",
    "goal = n.get_stream_goal(stream)\n",
    "target = torch.LongTensor(goal)\n",
    "\n",
    "l = BasicRNN(n.get_dim(), 5, n.get_dim(), 3)\n",
    "hid = l.init_hidden()\n",
    "\n",
    "the_out, the_hid = l.forward(enc_stream, hid)\n",
    "\n",
    "the_out[0,0,0] = -2#5\n",
    "the_out[1,0,5] = -2#5\n",
    "the_out[2,0,6] = -2#5\n",
    "\n",
    "loss = criterion(the_out.squeeze(1), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RM TEST1] act:tensor([ 0.5261, -1.5163, -0.6044,  0.5245]) exp:tensor([ 0.5261, -1.5163, -0.6044,  0.5245])\n",
      "[RM TEST2] act:tensor([ 0.1845, -0.4467,  0.1367, -0.5949]) exp:tensor([ 0.1845, -0.4467,  0.1367, -0.5949])\n",
      "[WM TEST1] act:tensor([-0.9003,  0.9227, -0.7564]) exp:tensor([-0.9003,  0.9227, -0.7564])\n",
      "[WM TEST2] act:tensor([1.1107, 3.1953, 1.5835]) exp:tensor([1.1107, 3.1953, 1.5835])\n",
      "[WM TEST3] act:tensor([0., 0., 0.]) exp:tensor([0., 0., 0.])\n",
      "[WM TEST4] act:tensor([ 1.8990, -0.5792,  0.9731,  0.5017, -0.8982,  0.1428,  1.1492, -0.0978,\n",
      "         0.2197,  1.9246,  1.2118, -1.0656,  1.6490, -0.5932, -0.5040,  1.5088,\n",
      "         0.0564,  2.4903, -0.4258, -0.0668, -1.1677, -0.6731, -1.2875,  1.8346,\n",
      "        -1.0690,  0.2515,  1.2229, -0.3647,  1.2093, -1.9404]) exp:tensor([ 1.8990, -0.5792,  0.9731,  0.5017, -0.8982,  0.1428,  1.1492, -0.0978,\n",
      "         0.2197,  1.9246,  1.2118, -1.0656,  1.6490, -0.5932, -0.5040,  1.5088,\n",
      "         0.0564,  2.4903, -0.4258, -0.0668, -1.1677, -0.6731, -1.2875,  1.8346,\n",
      "        -1.0690,  0.2515,  1.2229, -0.3647,  1.2093, -1.9404])\n",
      "[WM TEST5] act:tensor([-0.3109,  0.3985, -0.7006, -0.1124,  1.6395,  2.1390, -0.2633,  1.3893,\n",
      "         1.7145,  0.3980, -0.7204,  1.3121, -1.7015,  1.9961,  1.0343, -0.4547,\n",
      "        -0.2033, -0.2037,  1.7371,  0.5964,  0.6251, -0.3435,  0.6808, -0.9837,\n",
      "         0.9623, -0.5929, -1.9174, -0.2652, -0.8744,  0.6952]) exp:tensor([-0.3109,  0.3985, -0.7006, -0.1124,  1.6395,  2.1390, -0.2633,  1.3893,\n",
      "         1.7145,  0.3980, -0.7204,  1.3121, -1.7015,  1.9961,  1.0343, -0.4547,\n",
      "        -0.2033, -0.2037,  1.7371,  0.5964,  0.6251, -0.3435,  0.6808, -0.9837,\n",
      "         0.9623, -0.5929, -1.9174, -0.2652, -0.8744,  0.6952])\n"
     ]
    }
   ],
   "source": [
    "# READ_MEMORY TESTS\n",
    "mem = Memory(10,4)\n",
    "\n",
    "flat = torch.ones(10)\n",
    "just_4 = torch.zeros(10)\n",
    "just_4[4] = 1\n",
    "\n",
    "act = mem.read(just_4)\n",
    "exp = mem.memory[4]\n",
    "print(f'[RM TEST1] act:{act} exp:{exp}')\n",
    "\n",
    "act = mem.read(flat)\n",
    "exp = mem.memory.mean(dim=0)\n",
    "print(f'[RM TEST2] act:{act} exp:{exp}')\n",
    "\n",
    "# WRITE_MEMORY TESTS\n",
    "mem_dim = 3\n",
    "\n",
    "att_flat = torch.ones(10)\n",
    "att_just_4 = torch.zeros(10)\n",
    "att_just_4[4] = 1\n",
    "\n",
    "forget_ones = torch.ones(mem_dim)\n",
    "forget_half = torch.ones(mem_dim) / 2\n",
    "forget_zeros = torch.zeros(mem_dim)\n",
    "\n",
    "add_zero = torch.zeros(mem_dim)\n",
    "add_ones = torch.ones(mem_dim)\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = mem.memory[4]\n",
    "act = mem.write(att_just_4, forget_zeros, add_zero)[4]\n",
    "print(f'[WM TEST1] act:{act} exp:{exp}')\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = mem.memory[4] + 1\n",
    "act = mem.write(att_just_4, forget_zeros, add_ones)[4]\n",
    "print(f'[WM TEST2] act:{act} exp:{exp}')\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = torch.zeros_like(mem.memory[4])\n",
    "act = mem.write(att_just_4, forget_ones, add_zero)[4]\n",
    "print(f'[WM TEST3] act:{act} exp:{exp}')\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = mem.memory * (1 - 0.5 / 10)\n",
    "act = mem.write(att_flat, forget_half, add_zero)\n",
    "print(f'[WM TEST4] act:{act.view(-1)} exp:{exp.view(-1)}')\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = mem.memory * (1 - 0.5 / 10) + 0.1\n",
    "act = mem.write(att_flat, forget_half, add_ones)\n",
    "print(f'[WM TEST5] act:{act.view(-1)} exp:{exp.view(-1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
