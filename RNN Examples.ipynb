{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of RNN Approaches\n",
    "(see https://distill.pub/2016/augmented-rnns/)\n",
    "\n",
    "This creates a sample task, based on number sequences, and\n",
    "different goals to compare the performance of vanilla RNN's,\n",
    "LSTM's, NTM's, and attention based networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, einsum\n",
    "from random import randint\n",
    "from torch.nn import functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Numbers:\n",
    "    ''' This is a controller \n",
    "    \n",
    "    '''\n",
    "    def __init__(self, max_number = 9,\n",
    "                 increment_func = lambda stream: stream[-1]+1,\n",
    "                 reset_func = None,\n",
    "                 reset_value_func = lambda stream: 0,\n",
    "                 goal_func = lambda stream: stream[0]):\n",
    "        ''' Initialize the controller\n",
    "        Args:\n",
    "            increment_func: called on each number in the stream to decide\n",
    "                the next number in the stream\n",
    "            reset_func: evalutes the stream to determine if a reset\n",
    "                condition has been met causing a restart on a new number\n",
    "            reset_value_func: if a reset is triggered, this is called to\n",
    "                determine the new value to restart the stream with\n",
    "            goal_func: a function that returns the target output value\n",
    "                for the stream (i.e. the goal output)\n",
    "        '''\n",
    "        self.max_number = max_number\n",
    "        self.all_numbers = list(range(max_number+1))\n",
    "        self.all_classes = self.all_numbers + [-1]\n",
    "        \n",
    "        self.increment_func = increment_func\n",
    "        self.reset_func = reset_func\n",
    "        self.reset_value_func = reset_value_func\n",
    "        self.goal_func = goal_func\n",
    "        \n",
    "        \n",
    "    def create_stream(self, length, seed_stream = [0]):\n",
    "        ''' Create a stream (sequence) of numbers\n",
    "        \n",
    "        Args:\n",
    "            length: length of the stream to generate\n",
    "            seed_stream: seed stream to use in generating the first number\n",
    "                \n",
    "        Returns:\n",
    "            A sequence (list) of numbers in the stream\n",
    "        '''\n",
    "        if self.reset_func == None:\n",
    "            self.reset_func = lambda stream: stream[-1] == self.max_number\n",
    "    \n",
    "        start_num = self.reset_value_func(seed_stream)\n",
    "        stream = [start_num]\n",
    "        \n",
    "        for i in range(max(0,length-1)):\n",
    "            if self.reset_func(stream):\n",
    "                new_num = self.reset_value_func(stream)\n",
    "            else:\n",
    "                new_num = self.increment_func(stream)\n",
    "            stream.append(new_num)\n",
    "            \n",
    "        return stream\n",
    "    \n",
    "    \n",
    "    def encode_stream(self, num_stream):\n",
    "        ''' Converts number or number_stream into one-hot encoded tensor\n",
    "        An additional category is added for OTHER (unrecognized numbers)\n",
    "        \n",
    "        Args:\n",
    "            num_stream: A single number of sequence (list) of numbers\n",
    "                that will be encoded\n",
    "            \n",
    "        Returns:\n",
    "            Encoded tensor of shape (number_index, _, one_hot_encoded_number)\n",
    "        '''\n",
    "        num_stream = num_stream if type(num_stream) is list else [num_stream]\n",
    "        output = torch.zeros(len(num_stream), 1, len(self.all_numbers)+1)\n",
    "        \n",
    "        for i, num in enumerate(num_stream):\n",
    "            value = num if num in self.all_numbers else -1\n",
    "            ind = self.all_classes.index(value)\n",
    "            output[i,0,ind] = 1\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def get_stream_goal(self, stream):\n",
    "        ''' Return the goal output for the providede stream \n",
    "        Args:\n",
    "            stream: a list of numbers in the sequence\n",
    "        \n",
    "        Returns:\n",
    "            Simple evaluation of the goal function (type depends\n",
    "            on the goal function provided)\n",
    "        '''\n",
    "        return self.goal_func(stream)\n",
    "    \n",
    "    \n",
    "    def decode_row(self, encoded_number):\n",
    "        ''' Decode a one-hot encoded vector back to the number '''\n",
    "        ind = encoded_number.argmax()\n",
    "        value = self.all_numbers[ind] if ind in self.all_numbers else -1\n",
    "        return value\n",
    "    \n",
    "        \n",
    "    def get_dim(self):\n",
    "        ''' Return dimension of each encoded tensor '''\n",
    "        return len(self.all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, number_tool, criterion, optim, train_size = 100e3, stream_size = 200, print_interval = 1e3):\n",
    "    ''' Runs a full training pass for a given model '''\n",
    "    \n",
    "    train_size = int(train_size)\n",
    "    print_interval = int(print_interval)\n",
    "    error_sum = 0\n",
    "    model_device = next(model.parameters()).device\n",
    "\n",
    "    for i in range(train_size):\n",
    "        # Generate a new random sequence for training\n",
    "        stream = number_tool.create_stream(stream_size)\n",
    "        obs = number_tool.encode_stream(stream).to(model_device)\n",
    "\n",
    "        # Reset the model gradients and hidden layer\n",
    "        model.zero_grad()\n",
    "        hidden = model.init_hidden()\n",
    "        \n",
    "        # Score the model\n",
    "        output, hidden = model.forward(obs, hidden)\n",
    "\n",
    "        # Determine the target output and calculate the loss\n",
    "        goal = number_tool.get_stream_goal(stream)\n",
    "        target = torch.LongTensor([goal]).to(model_device)\n",
    "        loss = criterion(output.squeeze(0), target)\n",
    "        \n",
    "        # Run backprop with the errors and update model/trackers\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        error_sum += loss\n",
    "\n",
    "        if i % print_interval == 0:\n",
    "            print(f'[{i}] Error: {error_sum / print_interval}')\n",
    "            error_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    ''' Basic RNN with a softmax output layer '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        ''' Init the RNN '''\n",
    "        super(BasicRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.input_to_output = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.input_to_hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        ''' Run a forward path for a single number of sequence of numbers\n",
    "        \n",
    "        Returns:\n",
    "            output and hidden layer after last sequence input\n",
    "        '''\n",
    "        for i in range(input.shape[0]):\n",
    "            combined_input = torch.cat((input[i].unsqueeze(0), hidden), dim=2)\n",
    "            hidden = self.input_to_hidden(combined_input)\n",
    "            \n",
    "        output = self.input_to_output(combined_input)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        ''' Returns new hidden layers for the start of a new sequence '''\n",
    "        model_device = next(self.parameters()).device\n",
    "        return torch.zeros(1, 1, self.hidden_size).to(model_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    ''' Basic single-LSTM with output calculated using a single\n",
    "        linear layer with a softmax activation '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        ''' Init the LSTM '''\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        ''' Run a forward path for a single number of sequence of numbers\n",
    "        \n",
    "        Returns:\n",
    "            output and hidden layer after last sequence input\n",
    "        '''\n",
    "        # Hidden is made up of (hidden, cell_state)\n",
    "        history, hidden = self.lstm.forward(input, hidden)\n",
    "        output = self.hidden_to_output(hidden[0])\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        ''' Returns new hidden layers for the start of a new sequence '''\n",
    "        model_device = next(self.parameters()).device\n",
    "        return (\n",
    "            torch.randn(1, 1, self.hidden_size).to(model_device),\n",
    "            torch.randn(1, 1, self.hidden_size).to(model_device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    ''' Implements an attention-based memory system as outlined in\n",
    "        the Neural Turing Machine paper '''\n",
    "    \n",
    "    def __init__(self, banks, dim):\n",
    "        ''' Initialize the memory store\n",
    "        \n",
    "        Args:\n",
    "            banks: number of memory banks\n",
    "            dim: dimension of each memory bank\n",
    "        '''\n",
    "        self.memory = torch.zeros(banks, dim)\n",
    "        \n",
    "        \n",
    "    def read(self, weights):\n",
    "        ''' Reads stored memory based on the attention\n",
    "        \n",
    "        Args:\n",
    "            weights: attention for each cell (size: banks)\n",
    "            \n",
    "        Returns:\n",
    "            weighted memory output (size: dim)\n",
    "        '''\n",
    "        attention = f.normalize(weights, p=1, dim=0)\n",
    "        read = einsum('ij,i->j', (self.memory, attention))\n",
    "        return read\n",
    "    \n",
    "    \n",
    "    def write(self, weights, erase, add):\n",
    "        ''' Updates attented memory with the erase and add\n",
    "        \n",
    "        Args:\n",
    "            weights: attention paid to each cell (size: banks)\n",
    "            erase: forget percent for each position (size: dim)\n",
    "            add: amount to remember in each position (size: dim)\n",
    "        '''\n",
    "        attention = f.normalize(weights, p=1, dim=0)\n",
    "        forget = einsum('i,j->ij', (attention, erase.clamp(0,1)))\n",
    "        decay = torch.ones_like(forget) - forget\n",
    "        \n",
    "        remember = einsum('i,j->ij', (attention, add))\n",
    "        \n",
    "        self.memory = self.memory * decay + remember\n",
    "        \n",
    "    \n",
    "    def get_content_similarity(self, query, key_strength = 1):\n",
    "        ''' Provides similarity of query with each memory cell\n",
    "        \n",
    "        Args:\n",
    "            query: reference memory to search for (size: dim)\n",
    "            key_strength: scalar to amplify/attenuate attention\n",
    "        '''\n",
    "        similarity = f.cosine_similarity(self.memory, query, dim=1)\n",
    "        content_attention = f.softmax(key_strength * similarity, dim=0)\n",
    "        return content_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryNN(nn.Module):\n",
    "    def __init__(self, hidden_size, memory_banks, memory_dim):\n",
    "        ''' Initialize the Memory NN\n",
    "        \n",
    "        Args:\n",
    "            hidden_size: input size of the LSTM hidden layer\n",
    "            memory_banks: count of memory banks to include\n",
    "            memory_dim: dimension of each memory bank\n",
    "        '''\n",
    "        super(MemoryNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.banks = memory_banks\n",
    "        self.dim = memory_dim\n",
    "        \n",
    "        self.memory = Memory(memory_banks, memory_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        # For key_strength(1), sharpening(1), shift(3), key, erase, add\n",
    "        self.hidden_to_dim = nn.Linear(hidden_size, 1+1+3+3*memory_dim)\n",
    "        self.hidden_to_gate = nn.Linear(hidden_size, memory_banks)\n",
    "        \n",
    "    \n",
    "    def split_outputs(self, dim_output, banks_output):\n",
    "        ''' Splits network output into intuitive groupings\n",
    "        \n",
    "        Args:\n",
    "            dim_output: output in the memory_dim space\n",
    "            banks_output: output in the memory_banks space\n",
    "            \n",
    "        Returns:\n",
    "            dictionary with each conceptual group referenceable by key\n",
    "        '''\n",
    "        o = {}\n",
    "        o['key_strength'] = dim_output[0]\n",
    "        o['sharpening'] = dim_output[1]\n",
    "        o['shift'] = dim_output[2:5]\n",
    "        o['key'], o['erase'], o['add'] = self._split(dim_output[5:], self.dim)\n",
    "        o['gate'] = banks_output\n",
    "        \n",
    "        return o\n",
    "        \n",
    "        \n",
    "    def calculate_memory_weight(self, w_old, k, β, g, s, γ):\n",
    "        ''' Calculates the read/write weight for the memory\n",
    "        \n",
    "        Args:\n",
    "            w_old: output weight from last processes token\n",
    "            k: content key to use for similarity lookup in memory\n",
    "            β: coef to attenuate/amplify content key attention\n",
    "            g: interpolation gate to raise/lower mix of w_c/w_old\n",
    "            s: shift weights to convolve with w_g\n",
    "            γ: sharpening exponent for final weights\n",
    "        '''\n",
    "        w_c = self.memory.get_content_similarity(k, β)\n",
    "        w_g = self._interpolate(w_c, w_old, g)\n",
    "        w_tilde = self._convolve(w_g, s)\n",
    "        weight = self._sharpen(w_tilde, γ)\n",
    "        \n",
    "        return weight\n",
    "    \n",
    "        \n",
    "    def forward(self, hidden, last_weight):\n",
    "        ''' Runs the Memory network using the hidden layer output\n",
    "        \n",
    "        Args:\n",
    "            hidden: hidden layer output from LSTM to use as input\n",
    "        '''\n",
    "        dim_output = self.hidden_to_dim(hidden).squeeze()\n",
    "        gate_output = self.hidden_to_gate(hidden).squeeze()\n",
    "        \n",
    "        split_output = self.split_outputs(dim_output, gate_output)\n",
    "        split_output['shift'] = self.softmax(split_output['shift'])\n",
    "        split_output['gate'] = self.sigmoid(split_output['gate'])\n",
    "        \n",
    "        weight = self.calculate_memory_weight(\n",
    "            w_old = last_weight,\n",
    "            k = split_output['key'],\n",
    "            β = split_output['key_strength'],\n",
    "            g = split_output['gate'],\n",
    "            s = split_output['shift'],\n",
    "            γ = split_output['sharpening']\n",
    "        )\n",
    "        \n",
    "        read_weight = self.memory.read(weight)\n",
    "        \n",
    "        self.memory.write(\n",
    "            weight,\n",
    "            split_output['erase'],\n",
    "            split_output['add']\n",
    "        )\n",
    "        \n",
    "        return read_weight\n",
    "    \n",
    "    \n",
    "    def reset_memory(self):\n",
    "        ''' Resets the memory network for a new sequence\n",
    "        \n",
    "        Returns:\n",
    "            pair of (initial_memory, initial_weights)\n",
    "        '''\n",
    "        self.memory = Memory(self.banks, self.dim)\n",
    "        memory_read = torch.zeros(self.dim)\n",
    "        weight = torch.zeros(self.banks)\n",
    "        \n",
    "        return (memory_read, weight)\n",
    "    \n",
    "    def _split(self, tensor, size):\n",
    "        ''' Return a tensor split into chunks of length `size` '''\n",
    "        count = tensor.shape[0] // size\n",
    "        split = [tensor[i*size : (i+1)*size] for i in range(count)]\n",
    "        return split\n",
    "        \n",
    "    def _interpolate(self, w1, w2, w1_mix):\n",
    "        ''' Interpolate between two weights '''\n",
    "        return w1_mix*w1 + (1-w1_mix)*w2\n",
    "    \n",
    "    def _sharpen(self, w, exponent):\n",
    "        ''' Sharpen weight distribution '''\n",
    "        w_sharpened = w ** exponent\n",
    "        return w_sharpened / w_sharpened.sum()\n",
    "    \n",
    "    def _convolve(self, x, s):\n",
    "        ''' Implement circular convolution between w and s '''\n",
    "        # Create circular padding and reshape for conv2d\n",
    "        x2 = torch.cat((x[-1:], x, x[:1])).view(1,1,1,-1)\n",
    "        s2 = s.view(1,1,1,-1)\n",
    "\n",
    "        # Run circular convolution and undo reshaping\n",
    "        out = f.conv2d(x2, s2, padding=(0,1)).view(-1)\n",
    "\n",
    "        # Return without padding\n",
    "        return out[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTM_LSTM(nn.Module):\n",
    "    '''  '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, memory_banks, memory_dim):\n",
    "        ''' Init the NTM-LSTM '''\n",
    "        super(NTM_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.memory_banks = memory_banks\n",
    "        self.memory_dim = memory_dim\n",
    "        \n",
    "        # Core LSTM and Memory\n",
    "        self.lstm = nn.LSTM(input_size + memory_dim, hidden_size)\n",
    "        self.mem_nn = MemoryNN(hidden_size, memory_banks, memory_dim)\n",
    "        \n",
    "        # Output Layer\n",
    "        self.hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        self.output_softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, state):\n",
    "        ''' Run a forward path for a single number of sequence of numbers\n",
    "        \n",
    "        Args:\n",
    "            state: contains [hidden, cell, memory, last_weight]\n",
    "        \n",
    "        Returns:\n",
    "            output and hidden layer after last sequence input\n",
    "        '''\n",
    "        \n",
    "        hidden, cell, memory, weight = state\n",
    "        \n",
    "        for i in range(input.shape[0]):\n",
    "            ntm_input = torch.cat((input[i].unsqueeze(0), memory.view(1,1,-1)), dim=2)\n",
    "        \n",
    "            _, (hidden, cell) = self.lstm.forward(ntm_input, (hidden, cell))\n",
    "            memory, weight = self.mem_nn.forward(hidden, weight)\n",
    "        \n",
    "        output = self.hidden_to_output(hidden)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, (hidden, cell, memory, weight)\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        ''' Returns new hidden layers for the start of a new sequence '''\n",
    "        memory, weight = self.mem_nn.reset_memory()\n",
    "        \n",
    "        model_device = next(self.parameters()).device\n",
    "\n",
    "        return (\n",
    "            torch.randn(1, 1, self.hidden_size).to(model_device),\n",
    "            torch.randn(1, 1, self.hidden_size).to(model_device),\n",
    "            memory.to(model_device),\n",
    "            weight.to(model_device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number Generator + Goal Setup\n",
    "max_number = 9\n",
    "goal_func = lambda stream: stream[0]\n",
    "goal_dim = max_number+2\n",
    "\n",
    "number_tool = Numbers(max_number,\n",
    "                      reset_value_func = lambda x: randint(0,max_number),\n",
    "                      goal_func = goal_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Size\n",
    "train_size = 100e3\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_kwargs = {\n",
    "    'train_size': train_size,\n",
    "    'number_tool': number_tool,\n",
    "    'criterion': criterion,\n",
    "    'stream_size': 200,\n",
    "    'model': None,\n",
    "    'optim': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Vanilla RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = BasicRNN(number_tool.get_dim(), 5, goal_dim)\n",
    "rnn_optim = torch.optim.SGD(rnn.parameters(), lr = 0.001)\n",
    "\n",
    "rnn_kwargs = setup_kwargs.copy()\n",
    "rnn_kwargs['model'] = rnn\n",
    "rnn_kwargs['optim'] = rnn_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(**rnn_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BasicLSTM(number_tool.get_dim(), 5, goal_dim)\n",
    "lstm.to(device)\n",
    "\n",
    "lstm_optim = torch.optim.SGD(lstm.parameters(), lr = 0.001, momentum = 0.9)\n",
    "\n",
    "lstm_kwargs = setup_kwargs.copy()\n",
    "lstm_kwargs['model'] = lstm\n",
    "lstm_kwargs['optim'] = lstm_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(**lstm_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Turing Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_banks = 10\n",
    "memory_dim = 20\n",
    "\n",
    "ntm = NTM_LSTM(number_tool.get_dim(), 5, goal_dim, memory_banks, memory_dim)\n",
    "ntm_optim = torch.optim.SGD(ntm.parameters(), lr = 0.001)\n",
    "\n",
    "ntm_kwargs = setup_kwargs.copy()\n",
    "ntm_kwargs['model'] = ntm\n",
    "ntm_kwargs['optim'] = ntm_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m(2219)\u001b[0;36mcosine_similarity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2217 \u001b[0;31m    \u001b[0mw12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2218 \u001b[0;31m    \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2219 \u001b[0;31m    \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2220 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mw12\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2221 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-109-4106a6d0b543>\u001b[0m(53)\u001b[0;36mget_content_similarity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     51 \u001b[0;31m            \u001b[0mkey_strength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0mto\u001b[0m \u001b[0mamplify\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mattenuate\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     52 \u001b[0;31m        '''\n",
      "\u001b[0m\u001b[0;32m---> 53 \u001b[0;31m        \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m        \u001b[0mcontent_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_strength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     55 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mcontent_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.memory.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  query.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-bec561612fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'debug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mntm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-c6f1e290c6ff>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, number_tool, criterion, optim, train_size, stream_size, print_interval)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Score the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Determine the target output and calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-3224f7a0d597>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, state)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntm_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_to_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-7d06efa68390>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden, last_weight)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shift'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mγ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sharpening'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-7d06efa68390>\u001b[0m in \u001b[0;36mcalculate_memory_weight\u001b[0;34m(self, w_old, k, β, g, s, γ)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mγ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msharpening\u001b[0m \u001b[0mexponent\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         '''\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mw_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_content_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mβ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mw_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mw_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-4106a6d0b543>\u001b[0m in \u001b[0;36mget_content_similarity\u001b[0;34m(self, query, key_strength)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mkey_strength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0mto\u001b[0m \u001b[0mamplify\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mattenuate\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         '''\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mcontent_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_strength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontent_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(x1, x2, dim, eps)\u001b[0m\n\u001b[1;32m   2217\u001b[0m     \u001b[0mw12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m     \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2219\u001b[0;31m     \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2220\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw12\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "%debug\n",
    "train_model(**ntm_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_pad = torch.cat((x[-1:], x, x[:1]))\\n\\ns = s.view(1,1,1,3)\\nx_pad = x_pad.view(1,1,1,8)\\n\\nout = f.conv2d(x_pad, s, padding=(0,1))\\n\\nprint(s)\\nprint(x)\\n#print(x_pad)\\n#print(out)\\nprint(out.view(-1)[1:-1])\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "x_pad = torch.cat((x[-1:], x, x[:1]))\n",
    "\n",
    "s = s.view(1,1,1,3)\n",
    "x_pad = x_pad.view(1,1,1,8)\n",
    "\n",
    "out = f.conv2d(x_pad, s, padding=(0,1))\n",
    "\n",
    "print(s)\n",
    "print(x)\n",
    "#print(x_pad)\n",
    "#print(out)\n",
    "print(out.view(-1)[1:-1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4000, 0.0500, 0.5000, 0.0000, 0.0000, 0.0500])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0500, 0.4000, 0.0500, 0.5000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.tensor([1.,0.,0.])\n",
    "x = torch.tensor([0.40, .05, .50, 0, 0, .05])\n",
    "\n",
    "print(x)\n",
    "_convolve(x,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Functional Testing\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RM TEST1] act:tensor([ 0.5261, -1.5163, -0.6044,  0.5245]) exp:tensor([ 0.5261, -1.5163, -0.6044,  0.5245])\n",
      "[RM TEST2] act:tensor([ 0.1845, -0.4467,  0.1367, -0.5949]) exp:tensor([ 0.1845, -0.4467,  0.1367, -0.5949])\n",
      "[WM TEST1] act:tensor([-0.9003,  0.9227, -0.7564]) exp:tensor([-0.9003,  0.9227, -0.7564])\n",
      "[WM TEST2] act:tensor([1.1107, 3.1953, 1.5835]) exp:tensor([1.1107, 3.1953, 1.5835])\n",
      "[WM TEST3] act:tensor([0., 0., 0.]) exp:tensor([0., 0., 0.])\n",
      "[WM TEST4] act:tensor([ 1.8990, -0.5792,  0.9731,  0.5017, -0.8982,  0.1428,  1.1492, -0.0978,\n",
      "         0.2197,  1.9246,  1.2118, -1.0656,  1.6490, -0.5932, -0.5040,  1.5088,\n",
      "         0.0564,  2.4903, -0.4258, -0.0668, -1.1677, -0.6731, -1.2875,  1.8346,\n",
      "        -1.0690,  0.2515,  1.2229, -0.3647,  1.2093, -1.9404]) exp:tensor([ 1.8990, -0.5792,  0.9731,  0.5017, -0.8982,  0.1428,  1.1492, -0.0978,\n",
      "         0.2197,  1.9246,  1.2118, -1.0656,  1.6490, -0.5932, -0.5040,  1.5088,\n",
      "         0.0564,  2.4903, -0.4258, -0.0668, -1.1677, -0.6731, -1.2875,  1.8346,\n",
      "        -1.0690,  0.2515,  1.2229, -0.3647,  1.2093, -1.9404])\n",
      "[WM TEST5] act:tensor([-0.3109,  0.3985, -0.7006, -0.1124,  1.6395,  2.1390, -0.2633,  1.3893,\n",
      "         1.7145,  0.3980, -0.7204,  1.3121, -1.7015,  1.9961,  1.0343, -0.4547,\n",
      "        -0.2033, -0.2037,  1.7371,  0.5964,  0.6251, -0.3435,  0.6808, -0.9837,\n",
      "         0.9623, -0.5929, -1.9174, -0.2652, -0.8744,  0.6952]) exp:tensor([-0.3109,  0.3985, -0.7006, -0.1124,  1.6395,  2.1390, -0.2633,  1.3893,\n",
      "         1.7145,  0.3980, -0.7204,  1.3121, -1.7015,  1.9961,  1.0343, -0.4547,\n",
      "        -0.2033, -0.2037,  1.7371,  0.5964,  0.6251, -0.3435,  0.6808, -0.9837,\n",
      "         0.9623, -0.5929, -1.9174, -0.2652, -0.8744,  0.6952])\n"
     ]
    }
   ],
   "source": [
    "# READ_MEMORY TESTS\n",
    "mem = Memory(10,4)\n",
    "\n",
    "flat = torch.ones(10)\n",
    "just_4 = torch.zeros(10)\n",
    "just_4[4] = 1\n",
    "\n",
    "act = mem.read(just_4)\n",
    "exp = mem.memory[4]\n",
    "print(f'[RM TEST1] act:{act} exp:{exp}')\n",
    "\n",
    "act = mem.read(flat)\n",
    "exp = mem.memory.mean(dim=0)\n",
    "print(f'[RM TEST2] act:{act} exp:{exp}')\n",
    "\n",
    "# WRITE_MEMORY TESTS\n",
    "mem_dim = 3\n",
    "\n",
    "att_flat = torch.ones(10)\n",
    "att_just_4 = torch.zeros(10)\n",
    "att_just_4[4] = 1\n",
    "\n",
    "forget_ones = torch.ones(mem_dim)\n",
    "forget_half = torch.ones(mem_dim) / 2\n",
    "forget_zeros = torch.zeros(mem_dim)\n",
    "\n",
    "add_zero = torch.zeros(mem_dim)\n",
    "add_ones = torch.ones(mem_dim)\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = mem.memory[4]\n",
    "act = mem.write(att_just_4, forget_zeros, add_zero)[4]\n",
    "print(f'[WM TEST1] act:{act} exp:{exp}')\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = mem.memory[4] + 1\n",
    "act = mem.write(att_just_4, forget_zeros, add_ones)[4]\n",
    "print(f'[WM TEST2] act:{act} exp:{exp}')\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = torch.zeros_like(mem.memory[4])\n",
    "act = mem.write(att_just_4, forget_ones, add_zero)[4]\n",
    "print(f'[WM TEST3] act:{act} exp:{exp}')\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = mem.memory * (1 - 0.5 / 10)\n",
    "act = mem.write(att_flat, forget_half, add_zero)\n",
    "print(f'[WM TEST4] act:{act.view(-1)} exp:{exp.view(-1)}')\n",
    "\n",
    "mem = Memory(10, mem_dim)\n",
    "exp = mem.memory * (1 - 0.5 / 10) + 0.1\n",
    "act = mem.write(att_flat, forget_half, add_ones)\n",
    "print(f'[WM TEST5] act:{act.view(-1)} exp:{exp.view(-1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
